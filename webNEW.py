import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from scipy.signal import savgol_filter
from scipy.ndimage import median_filter
import re

# ==========================================
# 1. KI·∫æN TR√öC M·∫†NG RESNET (Gi·ªØ nguy√™n v2.1)
# ==========================================
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ResidualBlock, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(),
            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm1d(out_channels)
        )
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv1d(in_channels, out_channels, kernel_size=1),
                nn.BatchNorm1d(out_channels)
            )
    def forward(self, x):
        return torch.relu(self.conv(x) + self.shortcut(x))

class RamanResNet(nn.Module):
    def __init__(self, num_targets=4):
        super(RamanResNet, self).__init__()
        self.feature_extractor = nn.Sequential(
            nn.Conv1d(3, 64, kernel_size=7, stride=2, padding=3),
            nn.ReLU(),
            ResidualBlock(64, 64),
            ResidualBlock(64, 128),
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten()
        )
        self.regressor = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, num_targets)
        )
    def forward(self, x):
        features = self.feature_extractor(x)
        return self.regressor(features)

# ==========================================
# 2. H√ÄM TI·ªÄN X·ª¨ L√ù (ƒê·ªìng b·ªô v2.1)
# ==========================================
def preprocess_input(spectrum):
    clean = median_filter(spectrum, size=3)
    x = clean.reshape(1, -1)
    d1 = savgol_filter(x, window_length=15, polyorder=3, deriv=1)
    d2 = savgol_filter(x, window_length=15, polyorder=3, deriv=2)
    def snv(data):
        return (data - np.mean(data, axis=1, keepdims=True)) / (np.std(data, axis=1, keepdims=True) + 1e-8)
    x_proc = np.stack([snv(x), snv(d1), snv(d2)], axis=1)
    return torch.tensor(x_proc, dtype=torch.float32)

# ==========================================
# 3. C·∫§U H√åNH & LOAD DATA
# ==========================================
st.set_page_config(page_title="Raman Analyzer Pro v2.2", layout="wide")
MODEL_PATH = 'raman_resnet_v2.1.pth'
METADATA_PATH = 'Sugar_Concentrations.csv'

@st.cache_resource
def load_model():
    model = RamanResNet(num_targets=4)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))
    model.eval()
    return model

@st.cache_data
def load_meta():
    return pd.read_csv(METADATA_PATH)

try:
    model = load_model()
    df_meta = load_meta()
except Exception as e:
    st.error(f"‚ö†Ô∏è L·ªói h·ªá th·ªëng: {e}")
    st.stop()

# ==========================================
# 4. SIDEBAR - B·ªò L·ªåC TH√îNG MINH
# ==========================================
st.sidebar.header("üõ† ƒêi·ªÅu khi·ªÉn & T√¨m ki·∫øm")
uploaded_file = st.sidebar.file_uploader("1. T·∫£i file Spectra (.csv)", type="csv")

selected_sample = None

if uploaded_file:
    df_spec = pd.read_csv(uploaded_file)
    all_samples = df_spec.columns[1:].tolist()
    
    tab_search, tab_list = st.sidebar.tabs(["üîç T√¨m theo Gi·∫øng", "üìã Danh s√°ch g·ªëc"])
    
    with tab_list:
        selected_sample = st.selectbox("Ch·ªçn t·ª´ danh s√°ch cu·ªôn:", all_samples)

    with tab_search:
        # Ph√¢n t√°ch t√™n m·∫´u ƒë·ªÉ t·∫°o b·ªô l·ªçc (Regex ƒë·ªÉ b·∫Øt E4_3, v.v.)
        # T√™n m·∫´u: Sugar_Concentration_Test_52_E4_3_RD1_M1_R2
        try:
            # L·∫•y danh s√°ch Plate duy nh·∫•t
            plates = sorted(list(set([s.split('_')[5] for s in all_samples])))
            sel_plate = st.selectbox("Ch·ªçn Plate:", plates)
            
            # L·ªçc c√°c m·∫´u thu·ªôc Plate ƒë√≥
            plate_samples = [s for s in all_samples if s.split('_')[5] == sel_plate]
            
            # L·∫•y danh s√°ch H√†ng (A-H)
            rows = sorted(list(set([re.findall(r'[A-Z]', s.split('_')[4])[0] for s in plate_samples])))
            sel_row = st.select_slider("Ch·ªçn H√†ng (Row):", options=rows)
            
            # L·ªçc theo h√†ng
            row_samples = [s for s in plate_samples if s.split('_')[4].startswith(sel_row)]
            
            # L·∫•y danh s√°ch C·ªôt (1-12)
            cols = sorted(list(set([int(re.findall(r'\d+', s.split('_')[4])[0]) for s in row_samples])))
            sel_col = st.selectbox("Ch·ªçn C·ªôt (Column):", cols)
            
            # L·∫•y l·∫ßn l·∫∑p (Round/Rep)
            final_options = [s for s in row_samples if s.split('_')[4] == f"{sel_row}{sel_col}"]
            
            if final_options:
                selected_sample = st.radio("Ch·ªçn l·∫ßn ƒëo (Replicates):", final_options)
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y m·∫´u ph√π h·ª£p.")
        except:
            st.error("C·∫•u tr√∫c t√™n file kh√¥ng kh·ªõp v·ªõi b·ªô l·ªçc th√¥ng minh.")

# ==========================================
# 5. HI·ªÇN TH·ªä K·∫æT QU·∫¢ (Nh∆∞ c≈© nh∆∞ng ·ªïn ƒë·ªãnh h∆°n)
# ==========================================
if uploaded_file and selected_sample:
    spectrum = df_spec[selected_sample].values
    wavenumbers = df_spec.iloc[:, 0].values

    st.title(f"üî¨ Ph√¢n t√≠ch m·∫´u: {selected_sample}")
    col_plot, col_res = st.columns([1.3, 1])

    with col_plot:
        st.subheader("üìà ƒê·ªì th·ªã ph·ªï Raman")
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(wavenumbers, spectrum, color='lightgray', lw=1, label='Raw', alpha=0.5)
        clean = median_filter(spectrum, size=3)
        ax.plot(wavenumbers, clean, color='#008080', lw=1.5, label='Median Filtered')
        ax.set_xlabel("Wavenumber (cm-1)")
        ax.set_ylabel("Intensity")
        ax.legend()
        st.pyplot(fig)

    with col_res:
        st.subheader("üìä K·∫øt qu·∫£ AI vs Metadata")
        input_tensor = preprocess_input(spectrum)
        with torch.no_grad():
            preds = np.maximum(model(input_tensor).numpy()[0] * 375.0, 0)
        
        sugars = ["Sucrose", "Fructose", "Maltose", "Glucose"]
        target_cols = [f'{s} [ul]' for s in sugars]
        
        parts = selected_sample.split('_')
        cell_id = f"{parts[4]}_{parts[5]}"
        truth_row = df_meta[df_meta['Cell Number'] == cell_id]

        if not truth_row.empty:
            actuals = truth_row[target_cols].values[0]
            compare_df = pd.DataFrame({
                "Th√†nh ph·∫ßn": sugars,
                "Th·ª±c t·∫ø": np.round(actuals, 2),
                "AI D·ª± ƒëo√°n": np.round(preds, 2),
                "L·ªách": np.round(preds - actuals, 2)
            })
            st.table(compare_df)
            st.success(f"üíé MAE: {np.mean(np.abs(preds-actuals)):.2f} ¬µl")
        else:
            for s, p in zip(sugars, preds):
                st.metric(s, f"{p:.2f} ¬µl")

    # B·∫£ng Metrics hi·ªáu nƒÉng v2.1
    with st.expander("üìù Th√¥ng s·ªë hi·ªáu nƒÉng h·ªá th·ªëng (Model v2.1)"):
        st.table(pd.DataFrame({
            "ƒê∆∞·ªùng": sugars,
            "MAE": [2.77, 2.59, 2.76, 4.41],
            "R-squared": [0.9927, 0.9967, 0.9964, 0.9931]
        }))
else:
    st.info("üëã Ch√†o ƒë·∫°i ca! H√£y t·∫£i file CSV l√™n ƒë·ªÉ tr·∫£i nghi·ªám b·ªô l·ªçc t√¨m ki·∫øm m·ªõi.")

